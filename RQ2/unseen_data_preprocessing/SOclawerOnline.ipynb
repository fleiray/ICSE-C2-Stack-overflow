{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stackapi import StackAPI\n",
    "# import datetime\n",
    "# def fetch_java_questions_with_accepted_answers():\n",
    "#     \"\"\"\n",
    "#     1) Fetch Java questions with accepted answers, created between\n",
    "#        2024-04-30 and 2024-12-01, sorted by activity.\n",
    "#     2) For each question that has an accepted_answer_id, fetch that answer's body.\n",
    "#     3) Merge the accepted answer body into the question data.\n",
    "#     \"\"\"\n",
    "#     # 1) Convert \"2024-04-30\" and \"2024-12-01\" to Unix timestamps (UTC)\n",
    "#     dt_from = datetime.datetime(2024, 4, 30, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "#     dt_to   = datetime.datetime(2024, 12, 1, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "#     from_ts = int(dt_from.timestamp())  # 1714435200\n",
    "#     to_ts   = int(dt_to.timestamp())    # 1733011200\n",
    "\n",
    "#     # 2) Initialize a StackAPI instance for Stack Overflow\n",
    "#     #    Provide a \"key\" if you need more than 25 pages or a higher quota.\n",
    "#     #    Example: StackAPI(\"stackoverflow\", key=\"YOUR_KEY\", max_pages=999, page_size=100)\n",
    "#     so = StackAPI(\"stackoverflow\", max_pages=24, page_size=100)\n",
    "\n",
    "#     # 3) Fetch questions using the 'search/advanced' method\n",
    "#     #    - Use a filter that returns at least `question_id`, `accepted_answer_id`, `title`, etc.\n",
    "#     #    - The filter below is a generic example that includes accepted_answer_id in question objects.\n",
    "#     #      If you prefer, you can test out other filters or generate a custom one here:\n",
    "#     #      https://api.stackexchange.com/docs/filters\n",
    "#     results = so.fetch(\n",
    "#         \"search/advanced\",\n",
    "#         fromdate=from_ts,\n",
    "#         todate=to_ts,\n",
    "#         order=\"desc\",\n",
    "#         sort=\"activity\",\n",
    "#         accepted=True,\n",
    "#         tagged=\"java\",\n",
    "#         filter=\"!BH*SB7RHf1VETxwT*c9sSuQDUbK6wX\",  # Includes accepted_answer_id, question_id, etc. (example)\n",
    "#     )\n",
    "\n",
    "#     all_questions = results[\"items\"]  # A list of question dicts\n",
    "    \n",
    "#     # 4) Gather all accepted_answer_id values\n",
    "#     accepted_answer_ids = [q[\"accepted_answer_id\"] \n",
    "#                            for q in all_questions \n",
    "#                            if \"accepted_answer_id\" in q]\n",
    "\n",
    "#     # If no questions have accepted answers (unlikely), we can skip\n",
    "#     if not accepted_answer_ids:\n",
    "#         return all_questions\n",
    "\n",
    "#     # 5) Fetch the accepted answers, including their bodies\n",
    "#     #    (We must chunk into sets of up to 100 IDs per call, because the API limit is 100)\n",
    "#     answers_map = {}\n",
    "#     chunk_size = 100\n",
    "#     for i in range(0, len(accepted_answer_ids), chunk_size):\n",
    "#         chunk = accepted_answer_ids[i : i + chunk_size]\n",
    "#         chunk_str = \";\".join(map(str, chunk))  # e.g. \"1234;5678;91011\"\n",
    "        \n",
    "#         # Use the /answers/{ids} endpoint with a filter that includes 'body'.\n",
    "#         ans_results = so.fetch(\n",
    "#             f\"answers/{chunk_str}\",\n",
    "#             filter=\"withbody\"\n",
    "#         )\n",
    "#         # Map each answer_id to the answer object that includes the body\n",
    "#         for ans in ans_results.get(\"items\", []):\n",
    "#             answers_map[ans[\"answer_id\"]] = ans\n",
    "\n",
    "#     # 6) Merge the accepted answer body back into the question data\n",
    "#     for q in all_questions:\n",
    "#         a_id = q.get(\"accepted_answer_id\")\n",
    "#         if a_id and a_id in answers_map:\n",
    "#             # You can store the entire answer object or just the body\n",
    "#             q[\"accepted_answer_body\"] = answers_map[a_id][\"body\"]\n",
    "    \n",
    "#     return all_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions fetched: 2400\n",
      "\n",
      "Title: Apache Kafka Kraft - Cancelled in-flight API_VERSIONS request\n",
      "Question ID: 79099718\n",
      "Accepted Answer ID: 79314440\n",
      "Accepted Answer Body: <p>minikube + strimzi were really helpful althought a little harder to configure. I fixed this issue a longer time ago but have answered only now :D</p>\n",
      " ...\n",
      "\n",
      "Title: Find maximum length of up then down and up sequence of numbers\n",
      "Question ID: 79163186\n",
      "Accepted Answer ID: 79307192\n",
      "Accepted Answer Body: <h3>Observations</h3>\n",
      "<p>We need at least two distinct values to have a solution -- if this is not the case we cannot satisfy the constraints, namely that <em>&quot;Items from i to j should be in decreasing order strictly&quot;</em> and <em>&quot;i &lt; j&quot;</em>.</p>\n",
      "<p>The maximum value is a go ...\n",
      "\n",
      "Title: unable to fill an array with numbers from input in java\n",
      "Question ID: 78697257\n",
      "Accepted Answer ID: 78697307\n",
      "Accepted Answer Body: <p>You must declare the variable as an instance variable, but allocate the array after the number is read.</p>\n",
      "<pre><code>public class T4NumericalOperations {\n",
      "    Scanner input = new Scanner(System.in);\n",
      "    int n;\n",
      "    double[] numbers;   // declaration only\n",
      "\n",
      "    public void readNumbers(){\n",
      "        Sy ...\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     questions = fetch_java_questions_with_accepted_answers()\n",
    "#     print(\"Total questions fetched:\", len(questions))\n",
    "\n",
    "#     # Show sample\n",
    "#     if questions:\n",
    "#         for q in questions[:3]:\n",
    "#             print(\"\\nTitle:\", q[\"title\"])\n",
    "#             print(\"Question ID:\", q[\"question_id\"])\n",
    "#             print(\"Accepted Answer ID:\", q.get(\"accepted_answer_id\"))\n",
    "#             print(\"Accepted Answer Body:\", q.get(\"accepted_answer_body\", \"N/A\")[:300], \"...\")  # truncated\n",
    "#     else:\n",
    "#         print(\"No questions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# out_filename = \"java_questions_2024.json\"\n",
    "# with open(out_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(questions, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stackapi import StackAPI\n",
    "# import datetime\n",
    "# def fetch_python_questions_with_accepted_answers():\n",
    "#     \"\"\"\n",
    "#     1) Fetch Java questions with accepted answers, created between\n",
    "#        2024-04-30 and 2024-12-01, sorted by activity.\n",
    "#     2) For each question that has an accepted_answer_id, fetch that answer's body.\n",
    "#     3) Merge the accepted answer body into the question data.\n",
    "#     \"\"\"\n",
    "#     # 1) Convert \"2024-04-30\" and \"2024-12-01\" to Unix timestamps (UTC)\n",
    "#     dt_from = datetime.datetime(2024, 4, 30, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "#     dt_to   = datetime.datetime(2024, 12, 1, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "#     from_ts = int(dt_from.timestamp())  # 1714435200\n",
    "#     to_ts   = int(dt_to.timestamp())    # 1733011200\n",
    "\n",
    "#     # 2) Initialize a StackAPI instance for Stack Overflow\n",
    "#     #    Provide a \"key\" if you need more than 25 pages or a higher quota.\n",
    "#     #    Example: StackAPI(\"stackoverflow\", key=\"YOUR_KEY\", max_pages=999, page_size=100)\n",
    "#     so = StackAPI(\"stackoverflow\", max_pages=24, page_size=100)\n",
    "\n",
    "#     # 3) Fetch questions using the 'search/advanced' method\n",
    "#     #    - Use a filter that returns at least `question_id`, `accepted_answer_id`, `title`, etc.\n",
    "#     #    - The filter below is a generic example that includes accepted_answer_id in question objects.\n",
    "#     #      If you prefer, you can test out other filters or generate a custom one here:\n",
    "#     #      https://api.stackexchange.com/docs/filters\n",
    "#     results = so.fetch(\n",
    "#         \"search/advanced\",\n",
    "#         fromdate=from_ts,\n",
    "#         todate=to_ts,\n",
    "#         order=\"desc\",\n",
    "#         sort=\"activity\",\n",
    "#         accepted=True,\n",
    "#         tagged=\"python\",\n",
    "#         filter=\"!BH*SB7RHf1VETxwT*c9sSuQDUbK6wX\",  # Includes accepted_answer_id, question_id, etc. (example)\n",
    "        \n",
    "#     )\n",
    "\n",
    "#     all_questions = results[\"items\"]  # A list of question dicts\n",
    "    \n",
    "#     # 4) Gather all accepted_answer_id values\n",
    "#     accepted_answer_ids = [q[\"accepted_answer_id\"] \n",
    "#                            for q in all_questions \n",
    "#                            if \"accepted_answer_id\" in q]\n",
    "\n",
    "#     # If no questions have accepted answers (unlikely), we can skip\n",
    "#     if not accepted_answer_ids:\n",
    "#         return all_questions\n",
    "\n",
    "#     # 5) Fetch the accepted answers, including their bodies\n",
    "#     #    (We must chunk into sets of up to 100 IDs per call, because the API limit is 100)\n",
    "#     answers_map = {}\n",
    "#     chunk_size = 100\n",
    "#     for i in range(0, len(accepted_answer_ids), chunk_size):\n",
    "#         chunk = accepted_answer_ids[i : i + chunk_size]\n",
    "#         chunk_str = \";\".join(map(str, chunk))  # e.g. \"1234;5678;91011\"\n",
    "        \n",
    "#         # Use the /answers/{ids} endpoint with a filter that includes 'body'.\n",
    "#         ans_results = so.fetch(\n",
    "#             f\"answers/{chunk_str}\",\n",
    "#             filter=\"withbody\"\n",
    "#         )\n",
    "#         # Map each answer_id to the answer object that includes the body\n",
    "#         for ans in ans_results.get(\"items\", []):\n",
    "#             answers_map[ans[\"answer_id\"]] = ans\n",
    "\n",
    "#     # 6) Merge the accepted answer body back into the question data\n",
    "#     for q in all_questions:\n",
    "#         a_id = q.get(\"accepted_answer_id\")\n",
    "#         if a_id and a_id in answers_map:\n",
    "#             # You can store the entire answer object or just the body\n",
    "#             q[\"accepted_answer_body\"] = answers_map[a_id][\"body\"]\n",
    "    \n",
    "#     return all_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Page one by One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stackapi import StackAPI\n",
    "import datetime\n",
    "\n",
    "def fetch_java_questions_with_accepted_answers():\n",
    "    \"\"\"\n",
    "    1) Fetch Java questions with accepted answers, created between\n",
    "       2024-04-30 and 2024-12-01, sorted by activity.\n",
    "    2) For each question that has an accepted_answer_id, fetch that answer's body.\n",
    "    3) Merge the accepted answer body into the question data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Convert \"2024-04-30\" and \"2024-12-01\" to Unix timestamps (UTC)\n",
    "    dt_from = datetime.datetime(2024, 4, 30, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "    dt_to   = datetime.datetime(2024, 12, 1, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "    from_ts = int(dt_from.timestamp())  # 1714435200\n",
    "    to_ts   = int(dt_to.timestamp())    # 1733011200\n",
    "\n",
    "    # 2) Initialize a StackAPI instance for Stack Overflow\n",
    "    so = StackAPI(\"stackoverflow\", max_pages=1, page_size=100,key='rl_Z5DzVFwcrKfVvi76UxbCMioB1')\n",
    "\n",
    "    # 3) We'll iterate over pages manually\n",
    "    all_questions = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"Fetching page {page}...\")\n",
    "        results = so.fetch(\n",
    "            \"search/advanced\",\n",
    "            fromdate=from_ts,\n",
    "            todate=to_ts,\n",
    "            order=\"desc\",\n",
    "            sort=\"activity\",\n",
    "            accepted=True,\n",
    "            tagged=\"java\",\n",
    "            filter=\"!BH*SB7RHf1VETxwT*c9sSuQDUbK6wX\",\n",
    "            page=page,\n",
    "        )\n",
    "        # Accumulate questions\n",
    "        items = results.get(\"items\", [])\n",
    "        all_questions.extend(items)\n",
    "\n",
    "        # If `has_more` is False or we got no items, break\n",
    "        if not results.get(\"has_more\") or not items:\n",
    "            break\n",
    "\n",
    "        # Otherwise, keep going\n",
    "        page += 1\n",
    "\n",
    "    # 4) Gather all accepted_answer_id values\n",
    "    accepted_answer_ids = [q[\"accepted_answer_id\"]\n",
    "                           for q in all_questions\n",
    "                           if \"accepted_answer_id\" in q]\n",
    "\n",
    "    if not accepted_answer_ids:\n",
    "        return all_questions\n",
    "\n",
    "    # 5) Fetch the accepted answers in chunks\n",
    "    answers_map = {}\n",
    "    chunk_size = 100\n",
    "    for i in range(0, len(accepted_answer_ids), chunk_size):\n",
    "        chunk = accepted_answer_ids[i : i + chunk_size]\n",
    "        chunk_str = \";\".join(map(str, chunk))\n",
    "        \n",
    "        ans_results = so.fetch(\n",
    "            f\"answers/{chunk_str}\",\n",
    "            filter=\"withbody\"\n",
    "        )\n",
    "        for ans in ans_results.get(\"items\", []):\n",
    "            answers_map[ans[\"answer_id\"]] = ans\n",
    "\n",
    "    # 6) Merge the accepted answer body\n",
    "    for q in all_questions:\n",
    "        a_id = q.get(\"accepted_answer_id\")\n",
    "        if a_id and a_id in answers_map:\n",
    "            q[\"accepted_answer_body\"] = answers_map[a_id][\"body\"]\n",
    "\n",
    "    return all_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Fetching page 2...\n",
      "Fetching page 3...\n",
      "Fetching page 4...\n",
      "Fetching page 5...\n",
      "Fetching page 6...\n",
      "Fetching page 7...\n",
      "Fetching page 8...\n",
      "Fetching page 9...\n",
      "Fetching page 10...\n",
      "Fetching page 11...\n",
      "Fetching page 12...\n",
      "Fetching page 13...\n",
      "Fetching page 14...\n",
      "Fetching page 15...\n",
      "Fetching page 16...\n",
      "Fetching page 17...\n",
      "Fetching page 18...\n",
      "Fetching page 19...\n",
      "Fetching page 20...\n",
      "Fetching page 21...\n",
      "Fetching page 22...\n",
      "Fetching page 23...\n",
      "Fetching page 24...\n",
      "Fetching page 25...\n",
      "Fetching page 26...\n",
      "Fetching page 27...\n",
      "Fetching page 28...\n",
      "Total questions fetched: 2755\n",
      "\n",
      "Title: Keycloak Account API returns Unauthorized 401 with token from user logged in via my spring client\n",
      "Question ID: 78738348\n",
      "Accepted Answer ID: 78742682\n",
      "Accepted Answer Body: <blockquote>\n",
      "<p>What is the key difference between my spring boot app's client ... and the built-in keycloak &quot;account&quot; client ...??</p>\n",
      "</blockquote>\n",
      "<p>Clients roles. Go to clients details and open the <code>Roles</code> tab for the two.</p>\n",
      " ...\n",
      "\n",
      "Title: Understanding the GC profiler in JMH Java\n",
      "Question ID: 79144531\n",
      "Accepted Answer ID: 79310550\n",
      "Accepted Answer Body: <p>The answer to your second question is that an 'operation' is each invocation of the <code>@Benchmark</code> method (unless you override that by annotating the method with <code>@OperationsPerInvocation</code>), so yes, in your case, it is the number of calls to <code>creator.PiecewiseDNFModel</co ...\n",
      "\n",
      "Title: logback - show only errors in catalina.out\n",
      "Question ID: 79167258\n",
      "Accepted Answer ID: 79190460\n",
      "Accepted Answer Body: <h1>There are multiple <code>root</code> definitions and a reference to a &quot;CONSOLE&quot; appender that is not defined.</h1>\n",
      "<p>In the <code>logback-spring.xml</code> example you share there are multiple <code>root</code> definitions (<code>FILE-CATALINA</code>, <code>CONSOLE</code>, <code>STDOU ...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    questions = fetch_java_questions_with_accepted_answers()\n",
    "    print(\"Total questions fetched:\", len(questions))\n",
    "\n",
    "    # Show sample\n",
    "    if questions:\n",
    "        for q in questions[:3]:\n",
    "            print(\"\\nTitle:\", q[\"title\"])\n",
    "            print(\"Question ID:\", q[\"question_id\"])\n",
    "            print(\"Accepted Answer ID:\", q.get(\"accepted_answer_id\"))\n",
    "            print(\"Accepted Answer Body:\", q.get(\"accepted_answer_body\", \"N/A\")[:300], \"...\")  # truncated\n",
    "    else:\n",
    "        print(\"No questions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "out_filename = \"java_questions_2024_completed.json\"\n",
    "with open(out_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(questions, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stackapi import StackAPI\n",
    "import datetime\n",
    "\n",
    "def fetch_python_questions_with_accepted_answers():\n",
    "    \"\"\"\n",
    "    1) Fetch python questions with accepted answers, created between\n",
    "       2024-04-30 and 2024-12-01, sorted by activity.\n",
    "    2) For each question that has an accepted_answer_id, fetch that answer's body.\n",
    "    3) Merge the accepted answer body into the question data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Convert \"2024-04-30\" and \"2024-12-01\" to Unix timestamps (UTC)\n",
    "    dt_from = datetime.datetime(2024, 4, 30, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "    dt_to   = datetime.datetime(2024, 12, 1, 0, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "    from_ts = int(dt_from.timestamp())  # 1714435200\n",
    "    to_ts   = int(dt_to.timestamp())    # 1733011200\n",
    "\n",
    "    # 2) Initialize a StackAPI instance for Stack Overflow\n",
    "    so = StackAPI(\"stackoverflow\", max_pages=1, page_size=100,key='rl_Z5DzVFwcrKfVvi76UxbCMioB1')\n",
    "\n",
    "    # 3) We'll iterate over pages manually\n",
    "    all_questions = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"Fetching page {page}...\")\n",
    "        results = so.fetch(\n",
    "            \"search/advanced\",\n",
    "            fromdate=from_ts,\n",
    "            todate=to_ts,\n",
    "            order=\"desc\",\n",
    "            sort=\"activity\",\n",
    "            accepted=True,\n",
    "            tagged=\"python\",\n",
    "            filter=\"!BH*SB7RHf1VETxwT*c9sSuQDUbK6wX\",\n",
    "            page=page,\n",
    "        )\n",
    "        # Accumulate questions\n",
    "        items = results.get(\"items\", [])\n",
    "        all_questions.extend(items)\n",
    "\n",
    "        # If `has_more` is False or we got no items, break\n",
    "        if not results.get(\"has_more\") or not items:\n",
    "            break\n",
    "\n",
    "        # Otherwise, keep going\n",
    "        page += 1\n",
    "\n",
    "    # 4) Gather all accepted_answer_id values\n",
    "    accepted_answer_ids = [q[\"accepted_answer_id\"]\n",
    "                           for q in all_questions\n",
    "                           if \"accepted_answer_id\" in q]\n",
    "\n",
    "    if not accepted_answer_ids:\n",
    "        return all_questions\n",
    "\n",
    "    # 5) Fetch the accepted answers in chunks\n",
    "    answers_map = {}\n",
    "    chunk_size = 100\n",
    "    for i in range(0, len(accepted_answer_ids), chunk_size):\n",
    "        chunk = accepted_answer_ids[i : i + chunk_size]\n",
    "        chunk_str = \";\".join(map(str, chunk))\n",
    "        \n",
    "        ans_results = so.fetch(\n",
    "            f\"answers/{chunk_str}\",\n",
    "            filter=\"withbody\"\n",
    "        )\n",
    "        for ans in ans_results.get(\"items\", []):\n",
    "            answers_map[ans[\"answer_id\"]] = ans\n",
    "\n",
    "    # 6) Merge the accepted answer body\n",
    "    for q in all_questions:\n",
    "        a_id = q.get(\"accepted_answer_id\")\n",
    "        if a_id and a_id in answers_map:\n",
    "            q[\"accepted_answer_body\"] = answers_map[a_id][\"body\"]\n",
    "\n",
    "    return all_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Fetching page 2...\n",
      "Fetching page 3...\n",
      "Fetching page 4...\n",
      "Fetching page 5...\n",
      "Fetching page 6...\n",
      "Fetching page 7...\n",
      "Fetching page 8...\n",
      "Fetching page 9...\n",
      "Fetching page 10...\n",
      "Fetching page 11...\n",
      "Fetching page 12...\n",
      "Fetching page 13...\n",
      "Fetching page 14...\n",
      "Fetching page 15...\n",
      "Fetching page 16...\n",
      "Fetching page 17...\n",
      "Fetching page 18...\n",
      "Fetching page 19...\n",
      "Fetching page 20...\n",
      "Fetching page 21...\n",
      "Fetching page 22...\n",
      "Fetching page 23...\n",
      "Fetching page 24...\n",
      "Fetching page 25...\n",
      "Fetching page 26...\n",
      "Fetching page 27...\n",
      "Fetching page 28...\n",
      "Fetching page 29...\n",
      "Fetching page 30...\n",
      "Fetching page 31...\n",
      "Fetching page 32...\n",
      "Fetching page 33...\n",
      "Fetching page 34...\n",
      "Fetching page 35...\n",
      "Fetching page 36...\n",
      "Fetching page 37...\n",
      "Fetching page 38...\n",
      "Fetching page 39...\n",
      "Fetching page 40...\n",
      "Fetching page 41...\n",
      "Fetching page 42...\n",
      "Fetching page 43...\n",
      "Fetching page 44...\n",
      "Fetching page 45...\n",
      "Fetching page 46...\n",
      "Fetching page 47...\n",
      "Fetching page 48...\n",
      "Fetching page 49...\n",
      "Fetching page 50...\n",
      "Fetching page 51...\n",
      "Fetching page 52...\n",
      "Fetching page 53...\n",
      "Fetching page 54...\n",
      "Fetching page 55...\n",
      "Fetching page 56...\n",
      "Fetching page 57...\n",
      "Fetching page 58...\n",
      "Fetching page 59...\n",
      "Fetching page 60...\n",
      "Fetching page 61...\n",
      "Fetching page 62...\n",
      "Fetching page 63...\n",
      "Fetching page 64...\n",
      "Fetching page 65...\n",
      "Fetching page 66...\n",
      "Fetching page 67...\n",
      "Fetching page 68...\n",
      "Fetching page 69...\n",
      "Fetching page 70...\n",
      "Fetching page 71...\n",
      "Fetching page 72...\n",
      "Fetching page 73...\n",
      "Fetching page 74...\n",
      "Fetching page 75...\n",
      "Fetching page 76...\n",
      "Fetching page 77...\n",
      "Fetching page 78...\n",
      "Fetching page 79...\n",
      "Fetching page 80...\n",
      "Fetching page 81...\n",
      "Fetching page 82...\n",
      "Fetching page 83...\n",
      "Fetching page 84...\n",
      "Fetching page 85...\n",
      "Fetching page 86...\n",
      "Fetching page 87...\n",
      "Fetching page 88...\n",
      "Fetching page 89...\n",
      "Fetching page 90...\n",
      "Fetching page 91...\n",
      "Total questions fetched: 9016\n",
      "\n",
      "Title: Error 415 when trying to merge PDFs by stirlingpdf.io with python\n",
      "Question ID: 79224067\n",
      "Accepted Answer ID: 79355670\n",
      "Accepted Answer Body: <p><strong>Solved:</strong></p>\n",
      "<pre><code>filepaths = [r&quot;C:\\Users\\Public\\Documents\\data1.pdf&quot;,\n",
      "             r&quot;C:\\Users\\Public\\Documents\\data2.pdf&quot;]\n",
      "\n",
      "fileout = r&quot;C:\\Users\\Public\\Documents\\data3.pdf&quot;\n",
      "\n",
      "url = &quot;https://stirlingpdf.io/api/v1/general/merge-pdfs&quot;\n",
      "\n",
      "#  ...\n",
      "\n",
      "Title: Is there a clever way to convert a compex string to multiple lists in Python 3\n",
      "Question ID: 79211807\n",
      "Accepted Answer ID: 79211826\n",
      "Accepted Answer Body: <p>Use a  list comprehensions with <code>ast.literal_eval()</code></p>\n",
      "<pre><code>import ast\n",
      "\n",
      "sample_string = '[[15,&quot;name&quot;,12],[2002,&quot;another name&quot;,345]]'\n",
      "parsed_list = ast.literal_eval(sample_string)\n",
      "\n",
      "int_list1 = [item[0] for item in parsed_list]\n",
      "str_list = [item[1] for item in  ...\n",
      "\n",
      "Title: GPT LangChain experimental agent - allow dangerous code\n",
      "Question ID: 78712629\n",
      "Accepted Answer ID: 78713314\n",
      "Accepted Answer Body: <p>The referenced security notice is in <a href=\"https://api.python.langchain.com/en/latest/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html\" rel=\"nofollow noreferrer\">https://api.python.langchain.com/en/latest/agents/langchain_experimental.agents.ag ...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    questions = fetch_python_questions_with_accepted_answers()\n",
    "    print(\"Total questions fetched:\", len(questions))\n",
    "\n",
    "    # Show sample\n",
    "    if questions:\n",
    "        for q in questions[:3]:\n",
    "            print(\"\\nTitle:\", q[\"title\"])\n",
    "            print(\"Question ID:\", q[\"question_id\"])\n",
    "            print(\"Accepted Answer ID:\", q.get(\"accepted_answer_id\"))\n",
    "            print(\"Accepted Answer Body:\", q.get(\"accepted_answer_body\", \"N/A\")[:300], \"...\")  # truncated\n",
    "    else:\n",
    "        print(\"No questions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "out_filename = \"python_questions_2024_completed.json\"\n",
    "with open(out_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(questions, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
